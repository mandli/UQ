{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<table>\n",
    " <tr align=left><td><img align=left src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\">\n",
    " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license. (c) Kyle T. Mandli</td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.integrate\n",
    "import scipy.sparse as sparse\n",
    "import scipy.sparse.linalg as linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stochastic Spectral Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Purpose:** Construct surrogate (or Reduce Order Models) to help reduce the cost of UQ approaches.\n",
    "\n",
    "Examples:\n",
    " - Bayesian model calibration, sensitivity analysis, design and control.\n",
    " - Posterior density sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Key Idea:** Exploit smoothness of high-dimensional parameter spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Spectral Representation of Random Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Some definitions:\n",
    "\n",
    "- Define a sequence of random variables\n",
    "$$\n",
    "    \\left \\{ Q_k(\\omega) \\right \\}^\\infty_{k=1}\n",
    "$$\n",
    "on the sample space $\\Omega$ and probability space $(\\Omega, \\mathcal F, P)$.\n",
    "\n",
    "- Let $\\mathbb P_k$ denote space or polynomials with argument $Q_i$ with degree $\\leq k$.\n",
    "- Let $\\hat{\\mathcal P}_k \\in \\mathbb P_k$ s.t. $P \\in \\hat{\\mathcal P}_k$ are orthogonal to $\\mathbb P_{k-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Polynomial Expansions\n",
    "\n",
    "For a second order, finite-variance random variable $u$ can be represented as\n",
    "$$\n",
    "    u(\\omega) = u_0 \\hat{\\!P}_0 + \\sum^\\infty_{i_1 = 1} u_{i_1} \\hat{\\!P}_1(Q_{i_1}) + \\sum^\\infty_{i_1 = 1} \\sum^\\infty_{i_2 = 1} u_{i_1, i_2} \\hat{\\!P}_2(Q_{i_1}, Q_{i_2}) + \\sum^\\infty_{i_1 = 1} \\sum^\\infty_{i_2 = 1} \\sum^\\infty_{i_4 = 1} u_{i_1, i_2, i_3} \\hat{\\!P}_3(Q_{i_1}, Q_{i_2}, Q_{i_3}) + \\cdots\n",
    "$$\n",
    "Here $ \\hat{\\!P}_k(\\cdot)$ represent the interaction between variables and $u_{i_1}, u_{i_1, i_2}, \\ldots \\in \\mathbb R$.\n",
    "\n",
    "More succinctly this can be written as\n",
    "$$\n",
    "    u(Q) = \\sum^\\infty_{k=0} u_k \\Psi_k(Q_1, Q_2, Q_3, \\ldots)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we have a finite set of $\\left \\{Q_i\\right\\}^p_{k=1}$ then we have a finite sum that can represent $u(\\omega)$ up to $K$-order interactions as\n",
    "$$\n",
    "    u^K(Q) = \\sum^K_{k=0} u_k \\Psi_k(Q_1, Q_2, Q_3, \\ldots)\n",
    "$$\n",
    "where $K+1 = \\frac{(n+p)!}{n!p!}$.\n",
    "\n",
    "For example if the random variable $u$ has only second-order interactions and less we would have\n",
    "$$\n",
    "u(\\omega) = u_0 \\hat{\\!P}_0 + \\sum^\\infty_{i_1 = 1} u_{i_1} \\hat{\\!P}_1(Q_{i_1}) + \\sum^\\infty_{i_1 = 1} \\sum^\\infty_{i_2 = 1} u_{i_1, i_2} \\hat{\\!P}_2(Q_{i_1}, Q_{i_2})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now consider a random process $u(t, x, \\omega)$ where now we have also added possible time and spatial dependence.  Our polynomial representation then can be written as\n",
    "$$\n",
    "    u^K(t, x, Q) = \\sum^K_{k=0} u_k(t, x) \\Psi_k(Q)\n",
    "$$\n",
    "where we note that we have separated the time and spatial dependence from the random variables.  The $\\Psi_k$ are then usually looked as a orthogonal polynomial basis for the random part of the process $u$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example:**\n",
    "\n",
    "Consider a single random variable $Q \\in C_0$ and take $\\Psi_k(Q)$ as some set of one-dimensional polynomials that are orthogonal to each other with respect to the density $\\rho_Q(q)$ and normalized so that $\\Psi_0 = 1$.  Then\n",
    "$$\n",
    "    \\mathbb E[\\psi_0(Q)] = 1\n",
    "$$\n",
    "and\n",
    "$$\\begin{aligned}\n",
    "    \\mathbb E[\\psi_i(Q) \\psi_j(Q)] &= \\int \\psi_i(Q) \\psi_j(Q) \\rho_Q(q) dq \\\\\n",
    "    &= \\langle \\psi_i(Q) \\psi_j(Q) \\rangle_\\rho \\\\\n",
    "    &= \\delta_{ij} \\gamma_i\n",
    "\\end{aligned}$$\n",
    "\n",
    "Note that this is analogous to projecting onto an orthogonal polynomial basis.  Compute the mean and variance of the process $u(t, x, \\omega)$ given the above rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Mean:**\n",
    "$$\\begin{aligned}\n",
    "    \\mathbb E [u^K(t, x, Q)] &= \\mathbb E \\left [ \\sum^K_{k=0} u_k(t, x) \\psi_k(Q) \\right ] \\\\\n",
    "    &= u_0(t, x) \\mathbb E[\\psi_0(Q)] + \\sum^K_{k=1} u_k(t, x) \\mathbb E[\\psi_k(Q)] \\\\\n",
    "    &= u_0(t, x)\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Variance:**\n",
    "$$\\begin{aligned}\n",
    "    \\text{var} [u^K(t, x, Q)] &= \\mathbb E \\left [\\left ( u^K(t, x, Q) - \\mathbb E[u^K(t, x, Q)] \\right )^2 \\right] \\\\\n",
    "    &= \\mathbb E \\left [\\left(\\sum^K_{k=0} u_k(t, x) \\psi_k(Q) - u_0(t,x) \\right )^2 \\right ] \\\\\n",
    "    &= \\mathbb E \\left [\\left(u_0(t,x) + \\sum^K_{k=1} u_k(t, x) \\psi_k(Q) - u_0(t,x) \\right )^2 \\right ] \\\\\n",
    "    &= \\mathbb E \\left [\\left(\\sum^K_{k=1} u_k(t, x) \\psi_k(Q) \\right )^2 \\right ] \\\\\n",
    "    &= \\sum^K_{k=1} u^2_k(t, x)\\gamma_k\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Basis for Distributions\n",
    "\n",
    "As mentioned we want to have a polynomial basis that is orthogonal w.r.t. a density."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Normal Distribution** $Q \\sim N(0, 1)$\n",
    "$$\n",
    "    \\rho_Q(q) = \\frac{1}{\\sqrt{2 \\pi}} e^{-q^2 / 2}\n",
    "$$\n",
    "defined on $\\mathbb R$, use the Hermite polynomials:\n",
    "$$\\begin{aligned}\n",
    "    &H_0(Q) = 1, & & H_1(Q) = Q, & & H_2(Q) = Q^2 - 1, \\\\\n",
    "    &H_3(Q) = Q^3 - 3 Q, & & H_4(Q) = Q^4 - 6Q^2 + 3, & & H_5(Q) = Q^5 - 10 Q^3 + 15 Q, \\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "Normalization constants:\n",
    "$$\n",
    "    \\gamma_i = \\int_{\\mathbb R} \\psi^2(q) \\rho_Q(q)dq = i!\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Uniform Distribution** $Q \\sim \\mathcal{U}(-1, 1)$\n",
    "$$\n",
    "    \\rho_Q(q) = \\frac{1}{2}\n",
    "$$\n",
    "defined on $[-1, 1]$.\n",
    "For a uniform distribution we use the Legendre polynomials:\n",
    "$$\\begin{aligned}\n",
    "    &P_0(Q) = 1, & & P_1(Q) = Q, & & P_2(Q) = \\frac{3}{2} Q^2 - \\frac{1}{2}, \\\\\n",
    "    &P_3(Q) = \\frac{5}{2} Q^3 - \\frac{3}{2} Q, & & P_4(Q) = \\frac{35}{8} Q^4 - \\frac{15}{4} Q^2 + \\frac{3}{8}, & & P_5(Q) = \\frac{63}{8} Q^5 - \\frac{70}{8} Q^3 + \\frac{15}{8} Q, \\\\\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example:** Take $u \\sim N(\\mu, \\sigma^2)$ that can be represented as\n",
    "$$\n",
    "    u = \\mu + \\sigma Q\n",
    "$$\n",
    "where $Q \\sim N(0, 1)$.  Compute the coefficients of the polynomial representation of $u$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "    \\mu = \\mathbb E \\left [ \\sum^K_{k=0} u_k(t, x) \\psi_k(Q) \\right ] = u_0(t, x) \\Rightarrow u_0 = \\mu\n",
    "$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\sigma^2 &= \\mathbb E \\left [\\left ( u^K(t, x, Q) - \\mathbb E[u^K(t, x, Q)] \\right )^2 \\right] \\\\\n",
    "    &= \\sum^K_{k=1} u^2_k(t, x) \\gamma_k \\\\\n",
    "    &= u^2_1(t, x) \\gamma_1 \\Rightarrow u_1 = \\sigma\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example:** Take $u \\sim \\mathcal U(a, b)$ that has mean and variance\n",
    "$$\n",
    "    \\mu = \\frac{a+b}{2} \\quad \\quad \\sigma^2 = \\frac{(b - a)^2}{12}\n",
    "$$\n",
    "and can be expressed as\n",
    "$$\n",
    "    u = \\mu + \\sqrt{3} \\sigma Q\n",
    "$$\n",
    "where $Q \\sim \\mathcal{U}(-1, 1)$.  Compute the coefficients of the polynomial representation of $u$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Similarly to the case of a normal distribution we have\n",
    "$$\n",
    "    u_0 = \\mu = \\frac{a + b}{2}\n",
    "$$\n",
    "and\n",
    "$$\\begin{aligned}\n",
    "    u_1 = \\sqrt{3} \\sigma\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Multiple Random Variables\n",
    "\n",
    "The single random variable case naturally extends to multiple random variables if we assume that the variables are assumed to be independent of each other (not necessarily the case).  This implies that the expectation of their product is the expectation of the individual variables multiplied together and motivates the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A *p-dimensional Multi-Index* is a $p$-tuple where\n",
    "$$\n",
    "    \\boldsymbol{k'} = (k_1, \\ldots, k_p) \\in \\mathbb N^p_0\n",
    "$$\n",
    "of non-negative integers with magnitude\n",
    "$$\n",
    "    |\\boldsymbol{k'}| = \\sum^p_{i=1} k_i\n",
    "$$\n",
    "and are ordered such that\n",
    "$$\n",
    "    \\boldsymbol{j'} \\leq \\boldsymbol{k'} \\iff j_i \\leq k_i \\text{  for  } i=1, \\ldots, p.\n",
    "$$\n",
    "This is a bit hard to deal with but table 10.1 provides some values for the first few multi-indices as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "| $k$ | $|\\boldsymbol{k'}|$ | Multi-Index | Polynomial Multiplication              |\n",
    "|----------------------------------------------------------------------------------|\n",
    "|0    | 0                   | (0, 0, 0)   | $\\psi_0(Q_1) \\psi_0(Q_2) \\psi_0(Q_3)$  |\n",
    "|1    | 1                   | (1, 0, 0)   | $\\psi_1(Q_1) \\psi_0(Q_2) \\psi_0(Q_3)$  |\n",
    "|2    |                     | (0, 1, 0)   | $\\psi_0(Q_1) \\psi_1(Q_2) \\psi_0(Q_3)$  |\n",
    "|3    |                     | (0, 0, 1)   | $\\psi_0(Q_1) \\psi_0(Q_2) \\psi_1(Q_3)$  |\n",
    "|4    | 2                   | (2, 0, 0)   | $\\psi_2(Q_1) \\psi_0(Q_2) \\psi_1(Q_3)$  |\n",
    "|5    |                     | (1, 1, 0)   | $\\psi_1(Q_1) \\psi_1(Q_2) \\psi_1(Q_3)$  |\n",
    "|6    |                     | (1, 0, 1)   | $\\psi_1(Q_1) \\psi_0(Q_2) \\psi_1(Q_3)$  |\n",
    "|7    |                     | (0, 2, 0)   | $\\psi_0(Q_1) \\psi_2(Q_2) \\psi_0(Q_3)$  |\n",
    "|8    |                     | (0, 1, 1)   | $\\psi_0(Q_1) \\psi_1(Q_2) \\psi_1(Q_3)$  |\n",
    "|9    |                     | (0, 0, 2)   | $\\psi_0(Q_1) \\psi_0(Q_2) \\psi_2(Q_3)$  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now define a vector of random variables \n",
    "$$\n",
    "    Q = [Q_1,\\ldots,Q_p]\n",
    "$$ \n",
    "that are mutually independent with the density\n",
    "$$\n",
    "    \\rho_Q = \\prod^p_{i=1} \\rho_{Q_p}.\n",
    "$$\n",
    "\n",
    "Let the univariate basis functions of each $Q_i$ be\n",
    "$$\n",
    "    \\left \\{ \\psi_k(Q_i) \\right \\}^K_{k=0}\n",
    "$$\n",
    "is the univariate basis functions of degree $\\leq K$ for variable $Q_i$.  We can then form the multivariate basis as\n",
    "$$\n",
    "    \\Psi_{\\boldsymbol{i'}}(Q) = \\psi_{i_1}(Q_1), \\cdots \\psi_{i_p}(Q_p)\n",
    "$$\n",
    "for $0 \\leq |\\boldsymbol{i'}| \\leq K$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The resulting basis functions therefore satisfy\n",
    "$$\\begin{aligned}\n",
    "    \\mathbb E[\\Psi_{\\boldsymbol{i'}}(Q) \\Psi_{\\boldsymbol{j'}}(Q)] &= \\int \\Psi_{\\boldsymbol{i'}}(q) \\Psi_{\\boldsymbol{j'}}(q) \\rho_Q(q) dq \\\\\n",
    "    &= \\langle \\Psi_{\\boldsymbol{i'}}, \\Psi_{\\boldsymbol{j'}} \\rangle_\\rho \\\\\n",
    "    &= \\delta_{\\boldsymbol{i'} \\boldsymbol{j'}} \\gamma_{\\boldsymbol{i'}}\n",
    "\\end{aligned}$$\n",
    "where\n",
    "$$\n",
    "    \\gamma_{\\boldsymbol{i'}} = \\mathbb{E}[\\Psi^2_{\\boldsymbol{i'}}] = \\gamma_{i_1} \\cdots \\gamma_{i_p}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Turning back now to the representation of our process we have for $u(t, x, Q)$ the expansion\n",
    "$$\n",
    "    u^K(t, x, Q) = \\sum^K_{|\\boldsymbol{k'}| = 0} u_{\\boldsymbol{k'}}(t, x) \\Psi_{\\boldsymbol{k'}}(Q),\n",
    "$$\n",
    "again the projection of u(t, x, Q) onto the basis $\\Psi_{\\boldsymbol{k'}}$.  Moreover the orthogonality of the basis functions allow us to write down\n",
    "$$\n",
    "    u_k(t,x) = \\frac{1}{\\gamma_k} \\mathbb E[u(t, x, Q) \\Psi_k(Q) ]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Moreover the orthogonality of the basis functions allow us to write down\n",
    "$$\n",
    "    u_k(t,x) = \\frac{1}{\\gamma_k} \\mathbb E[u(t, x, Q) \\Psi_k(Q) ]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Galerkin, Collocation, and Discrete Projection Frameworks\n",
    "\n",
    "We now turn to ways to compute the $u_k(t,x) using constraints provided by the assumptions of each approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Finite Elements\n",
    "\n",
    "As an aside we will briefly describe the relatively similar notation and ideas from finite elements and how they will relate to the methods for computing the coefficients $u_k(t, x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider the simple ODE\n",
    "$$\n",
    "    \\frac{\\text{d}^2 u}{\\text{d}x^2} = f(x) \\quad x \\in \\Omega \\quad u|_{\\partial \\Omega} = \\Gamma(x).\n",
    "$$\n",
    "\n",
    "The first thing we will do is write the equation above, a.k.a. the *strong-form* of the equation, in the *weak-form* instead.  We do this by multiplying by a test function $v$ that satisfies the boundary conditions $v|_{\\partial \\Omega} = 0$ (you can also require $u$ to do this) and integrating to find\n",
    "$$\n",
    "    \\int_{\\Omega} u''(x) v(x) dx = \\int_{\\Omega} v(x) f(x) dx.\n",
    "$$\n",
    "\n",
    "Integrating the LHS by parts leads to\n",
    "$$\\begin{aligned}\n",
    "    u'(x) v(x) |_{\\partial \\Omega} - \\int_{\\Omega} u'(x) v'(x) dx &= \\int_{\\Omega} v(x) f(x) dx. \\\\\n",
    "    - \\int_{\\Omega} u'(x) v'(x) dx &= \\int_{\\Omega} v(x) f(x) dx.\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Since the weak-form of the equation should be true $\\forall v \\in H^1_0(\\Omega)$ such that we can restate the problem as \n",
    "$$\n",
    "    \\text{find a } u \\in H^1_0(\\Omega) \\quad \\forall v \\in H^1_0(\\Omega) \\quad \\int_{\\Omega} u'(x) v'(x) dx = \\int_{\\Omega} v(x) f(x) dx.\n",
    "$$\n",
    "This is an infinite dimensional problem and where discretization occurs.  Instead of the above problem we replace the Sobolev space with a finite dimensional space $V$ such that the problem is now to\n",
    "$$\n",
    "    \\text{find a } u \\in U \\quad \\forall v \\in V \\quad \\int_{\\Omega} u'(x) v'(x) dx = \\int_{\\Omega} v(x) f(x) dx.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For finite element methods we generally pick compactly support (with regards to the domain) piece-wise defined polynomials such as the hat functions\n",
    "$$\n",
    "    \\psi_i(x) = \\left \\{ \\begin{aligned}\n",
    "        &\\frac{x - x_{i-1}}{x_i - x_{i-1}} & & \\text{if } x \\in [x_{i-1}, x_i] \\\\\n",
    "        &\\frac{x_{i+1} - x}{x_{i+1} - x_{i}} & & \\text{if } x \\in [x_{i}, x_{i+1}] \\\\\n",
    "        &0 & & \\text{otherwise}\n",
    "    \\end{aligned} \\right .\n",
    "$$\n",
    "Note with this example that the basis is orthogonal at the nodes of the grid $x_i$ and have overlapping support in the intervals between nodes.  Other choices, such as the Fourier basis, lead to other methods such as spectral methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The final element (heh) of turning the problem above into a discretization is to write the solution $u$ as\n",
    "$$\n",
    "    u \\approx U = \\sum^K_{k=0} u_k \\psi_k(x)\n",
    "$$\n",
    "or in other words assume that the $\\psi_k(x) \\in \\Psi$ spans the space $U$.\n",
    "\n",
    "Plugging this back into the weak form we have\n",
    "$$\\begin{aligned}\n",
    "    \\int_{\\Omega} u'(x) v'(x) dx &= \\int_{\\Omega} v(x) f(x) dx \\\\\n",
    "    \\int_{\\Omega}  v'(x) \\sum^K_{k=0} u_k  \\psi_k'(x) dx &= \\int_{\\Omega} v(x) f(x) dx\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We now have to identify the space $V$.  A Galerkin method (also sometimes called model finite elements) assumes that the same set of basis functions also spans the space $V$ (or in most cases that $U = V$).  This then turns the weak form into\n",
    "$$\\begin{aligned}\n",
    "    \\int_{\\Omega}  \\psi_j'(x) \\sum^K_{k=0} u_k  \\psi_k'(x) dx &= \\int_{\\Omega} \\psi_j(x) f(x) dx \\quad \\forall \\psi_j \\in \\Psi \\\\\n",
    "    \\sum^K_{k=0} u_k \\int_{\\Omega}  \\psi_j'(x) \\psi_k'(x) dx &= \\int_{\\Omega} \\psi_j(x) f(x) dx \\quad \\forall \\psi_j \\in \\Psi\n",
    "\\end{aligned}$$\n",
    "for suitable assumptions.  This last expression can then be understood as a matrix problem on the LHS with the entries in the matrix comprised of\n",
    "$$\n",
    "    A_{jk} = \\int_{\\Omega} \\psi_j'(x) \\psi_k'(x) dx\n",
    "$$\n",
    "and the RHS the projection of $f(x)$ onto the space $\\Psi$ giving us the discretized problem\n",
    "$$\n",
    "    A U = f.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One way to think of the finite dimensional problem is to think of the problem as we have defined it as a projection onto the function space $U$ and $V$.  The function $f(x)$ is being projected onto $V$ and $U$ defines the space of functions we can look at to solve the problem (the search space).  If a problem converges to the true solution then $U \\rightarrow H$ where $H$ contains the true solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are three different ways we will approach this problem:\n",
    " - *Stochastic Galerkin Approach:*  This proceeds as we did with the finite element discussion and is equivalent to minimizing the residual onto a finite subspace.  Unfortunately things are not so easy when we switch back to our spectral representation of our process.  Instead the projection now requires the computation of expectations that are not usually needed in a deterministic setting.  This is often then called an *intrusive* method.\n",
    " - *Collocation:*  An alternative to Galerkin approaches is collocation or nodal methods.  Here we approximate the solution at a discrete set of points, called nodes or collocation points, and a space of polynomials $\\Psi$ such that the problem we try to solve is what $\\psi \\in \\Psi$ approximates the solution at the nodes the best.  This approach is considered *non-intrusive* as existing collocation approaches can be used.  Note that collocation approaches can be thought of as a specific type of Galerkin method.\n",
    " - *Discrete Projection:*  Direct approximation of the integral for the coefficients is used and can often be seen as another form of a Galerkin approach.  This approach often needs to be implemented independently but not always.\n",
    " \n",
    "We now turn to studying these three methods applied to problems of varying complexity via examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Scalar Initial Value Problem\n",
    "\n",
    "Consider the initial value problem\n",
    "$$\n",
    "    \\frac{\\text{d} u}{\\text{d}t} = f(t, Q, u) \\quad t > 0 \\quad u(0, Q) = u_0.\n",
    "$$\n",
    "Assume $Q = [Q_1,\\ldots,Q_p]$ are mutually independent random variables with range $\\Gamma \\in \\mathbb R^p$ and joint density $\\rho_Q(q)$.  Take the QoI as\n",
    "$$\n",
    "    y(t) = \\int_{\\Gamma} u(t, q) \\rho_Q(q) dq\n",
    "$$\n",
    "and solutions $u \\in L^2(0, T)$.  We also assume that we will be dealing with spaces of functions that have finite norm w.r.t. the $i$th component of the density such that if\n",
    "$$\n",
    "    ||g||_2 = \\left(\\int_{\\Gamma_i} |g(q_i)|^2 \\rho_{Q_i}(q_i) dq_i \\right)^{1/2} < \\infty.\n",
    "$$\n",
    "then $g \\in L^2_{\\rho_i}(\\Gamma_i)$.  We can then consider the composed space of functions \n",
    "$$\n",
    "    L^2_\\rho(\\Gamma) = L^2_{\\rho_1}(\\Gamma_1) \\otimes \\cdots \\otimes L^2_{\\rho_p}(\\Gamma_p).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let $\\{\\Psi_k\\}^K_{k=1}$ be a basis of a finite subspace $Z^K \\subset L^2_\\rho(\\Gamma)$ such that we can project $u(t, Q)$ onto $Z^K$ to find\n",
    "$$\n",
    "    u^K(t, Q) = \\sum^K_{k=0} u_k(t) \\Psi_k(Q).\n",
    "$$\n",
    "The resulting coefficients can be computed by\n",
    "$$\n",
    "    u_k(t) = \\frac{1}{\\gamma_k} \\int_\\Gamma u(t, q) \\Psi_k(q) \\rho_Q(q) dq.\n",
    "$$\n",
    "We can now turn to finding ways to approximate the above integral for the coefficients.  The coefficients $\\gamma_k$ can be computed as we have seen before with\n",
    "$$\n",
    "    \\gamma_k = \\langle \\psi_k, \\psi_k \\rangle_\\rho\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Stochastic Galerkin\n",
    "\n",
    "The basic problem formulation we need for this method is to make the projection of the residual\n",
    "$$\n",
    "    r = \\frac{\\text{d} u^K}{\\text{d}t} - f\n",
    "$$\n",
    "onto the basis function $\\psi_i$ so that in the basis considered so that the residual is orthogonal to the basis functions considered.  This can be formulated as\n",
    "$$\\begin{aligned}\n",
    "    0 &= \\left \\langle \\frac{\\text{d} u^K}{\\text{d}t} - f, \\psi_i \\right \\rangle_\\rho \\\\\n",
    "    &= \\int_\\Gamma \\left [ u^K(t, Q) - f\\left(t, q, u^K(t, Q) \\right ) \\right ] \\Psi_i(q) \\rho_Q(q)  dq \\\\\n",
    "    &= \\int_\\Gamma \\left [ \\sum^K_{k=0} \\frac{\\text{d} u_k}{\\text{d}t} \\Psi_k(q) - f\\left(t, q, \\sum^K_{k=0} u_k(t) \\Psi_k(q) \\right ) \\right ] \\Psi_i(q) \\rho_Q(q) dq \\quad \\quad \\forall i \\leq K\n",
    "\\end{aligned}$$\n",
    "\n",
    "Initial conditions are projected onto the the basis we constructed on $L^2_p(\\Gamma)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Discretization of the problem\n",
    "$$\n",
    "    \\int_\\Gamma \\left [ \\sum^K_{k=0} \\frac{\\text{d} u_k}{\\text{d}t} \\Psi_k(q) - f\\left(t, q, \\sum^K_{k=0} u_k(t) \\Psi_k(q) \\right ) \\right ] \\Psi_i(q) \\rho_Q(q) dq \\quad \\quad \\forall i \\leq K\n",
    "$$\n",
    "then requires a quadrature rule with points in $q^r \\in Q$ and weights $w^r$ so that we obtain\n",
    "$$\n",
    "    \\sum^R_{r=1} \\Psi_i(q^r) \\rho_Q(q^r) w^r \\left [\\sum^K_{k=0} \\frac{\\text{d} u_k}{\\text{d}t} \\Psi_k(q) - f\\left(t, q, \\sum^K_{k=0} u_k(t) \\Psi_k(q) \\right ) \\right ] = 0\n",
    "$$\n",
    "At this point many different quadrature methods can be used to find the $q^r$ and $w^r$.  For low-dimensional $Q$ straight-forward tensorial quadratures can be used.  For higher-dimensional spaces or more difficult problems (large gradients) other more sophisticated methods may be needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Collocation\n",
    "\n",
    "For collocation we choose a set of points in the parameter space $q^r \\in Q$, say $m \\in M$ samples such that\n",
    "$$\n",
    "    u(t, q^m) = u^K(t, q^m)\n",
    "$$\n",
    "This provides a set of constraints\n",
    "$$\n",
    "    \\begin{bmatrix}\n",
    "        \\Psi_0(q^1) & \\cdots & \\Psi_K(q^1) \\\\\n",
    "        \\vdots &  & \\vdots \\\\\n",
    "        \\Psi_0(q^M) & \\cdots & \\Psi_K(q^M) \\\\\n",
    "    \\end{bmatrix} \\begin{bmatrix}\n",
    "        u_0(t) \\\\ \\vdots \\\\ u_K(t)\n",
    "    \\end{bmatrix} = \n",
    "    \\begin{bmatrix}\n",
    "        u(t, q^1) \\\\ \\vdots \\\\ u(t, q^M)\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The size of the system needs to be $M \\geq K + 1$ so that it is not underdetermined.  It could in fact be advantageous to chose $M > K + 1$ although it may no longer be possible to fit solve the system without using a least-squares approach, something that is often done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Two difficulties with this approach:\n",
    "1. Choosing the collocation points $q^m$ can be non-trivial.  Again, for smaller parameter spaces this can simply be a tensorial discretization of $Q$.  For higher-dimensional or more complex spaces adaptive methods may need to be used.\n",
    "1. The choice of basis function can also lead to dense and ill-conditioned matrices.  To avoid this one can use Lagrange basis where\n",
    "$$\n",
    "    L_k(q^m) = \\delta_{km}\n",
    "$$\n",
    "leading to an identity matrix if the system is not over-determined.  Note that this only works when one uses the points for which the collocation and the basis evaluation points agree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Discrete Projection\n",
    "\n",
    "The final discretization uses a direct approximation of the terms as defined (also called a pseudo-spectral method).  In this case we can approximate the problem as\n",
    "$$\n",
    "    u_k(t) = \\frac{1}{\\gamma_k} \\sum^R_{r=1} u(t, q^r) \\Psi_k(q^r) \\rho_Q(q^r) w^r\n",
    "$$\n",
    "This formulation is more or less equivalent to the computational effort required for the collocation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Scalar initial value problem \n",
    "\n",
    "(Example 10.9 in Smith)\n",
    "\n",
    "$$\\frac{du}{dt} = -a(\\omega) u$$\n",
    "\n",
    "$$u(t=0,\\omega) = b$$\n",
    "\n",
    "$$a \\sim N(a_0,\\sigma_a^2)$$\n",
    "\n",
    "The damping rate $a$ is random with $a_0 = 1$, $\\sigma_a = 0.25$. The initial condition is fixed and deterministic $b=b_0 = 10$. \n",
    "\n",
    "The analytical solution is $$u(t) = b e^{-at}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "a0 = 1\n",
    "sigma_a = 0.25\n",
    "b0 = 10\n",
    "\n",
    "# Exact solution\n",
    "def u(b, a, t):\n",
    "    return b * numpy.exp(-a * t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Closed-form expressions for the mean and variance.\n",
    "$$E[u(t)] = b e^{-a_0 t} e^{\\sigma_a^2 t^2/2}$$\n",
    "\n",
    "$$var[u(t)] = e^{-2a_0 t} b^2 (e^{2 \\sigma_a^2 t^2} - e^{\\sigma_a^2 t^2})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "nt = 100\n",
    "t = numpy.linspace(0, 12, nt)\n",
    "t2 = t.reshape(nt,1)\n",
    "umean_exact = b0 * numpy.exp(-a0 * t) * numpy.exp(sigma_a**2 * t**2 / 2)\n",
    "uvar_exact = b0**2 * numpy.exp(-2 * a0 * t) * (numpy.exp(2 * sigma_a**2 * t**2) - numpy.exp(sigma_a**2 * t**2))\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "axes.plot(t, umean_exact, 'k', label='exact')\n",
    "axes.plot(t, umean_exact + 2 * numpy.sqrt(uvar_exact), 'k--')\n",
    "axes.plot(t, umean_exact - 2 * numpy.sqrt(uvar_exact), 'k--')\n",
    "axes.set_xlabel('Time (s)')\n",
    "axes.set_ylabel('Displacement (m)')\n",
    "axes.legend(['Mean'], loc=\"upper right\")\n",
    "axes.set_title('2-$\\sigma$ credible intervals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Direct simulation\n",
    "\n",
    "Sample damping rates and compute trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots()\n",
    "axes.plot(t, u(b0, numpy.random.normal(a0, sigma_a, 1000), t2))\n",
    "axes.set_xlabel('Time (s)')\n",
    "axes.set_ylabel('Displacement (m)')\n",
    "plt.show()\n",
    "\n",
    "Nsamples = 100000\n",
    "udirect = u(b0, numpy.random.normal(a0, sigma_a, Nsamples), t2)\n",
    "umean = numpy.mean(udirect,axis=1)\n",
    "uplus = umean + 2 * numpy.std(udirect, axis=1)\n",
    "uminus = umean - 2 * numpy.std(udirect, axis=1)\n",
    "\n",
    "fig, axes  = plt.subplots()\n",
    "axes.plot(t, umean, label='simulation')\n",
    "axes.plot(t, uplus)\n",
    "axes.plot(t, uminus)\n",
    "axes.plot(t, umean_exact, 'k--',label='exact')\n",
    "axes.plot(t, umean_exact + 2 * numpy.sqrt(uvar_exact), 'k--')\n",
    "axes.plot(t, umean_exact - 2 * numpy.sqrt(uvar_exact), 'k--')\n",
    "axes.set_xlabel('Time (s)')\n",
    "axes.set_ylabel('Displacement (m)')\n",
    "axes.legend(['Mean'], loc=\"upper right\")\n",
    "axes.set_title('2-$\\sigma$ credible intervals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note the intervals grow and become unbounded for large $t$ because some of the damping rates are negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Stochastic Spectral\n",
    "\n",
    "We seek approximate solutions $$u^K(t,Q) = \\sum_{k=0}^K u_k(t) \\psi_k(Q)$$\n",
    "Subject to $$\\left\\langle \\frac{du^K}{dt} + a^N u^K,\\psi_i \\right\\rangle_\\rho = 0\\,, \\qquad i=0,\\dots, K$$\n",
    "Or\n",
    "$$\\left\\langle \\frac{du^K}{dt},\\psi_i \\right\\rangle_\\rho = \\left\\langle_\\rho a^N u^K,\\psi_i \\right\\rangle_\\rho \\,, \\qquad i=0,\\dots, K$$\n",
    "Or\n",
    "$$ \\int \\sum_{k=0}^K \\frac{d u_k}{dt} (t) \\psi_k(q) \\psi_i(q) \\rho_Q(q) dq = \\int a^N(q) \\sum_{k=0}^K u_k(t) \\psi_k(q) \\psi_i(q) \\rho_Q(q) dq$$\n",
    "$$ a^N(q) = \\sum_{n=0}^N a_n \\psi_n(q) = a_0 + \\sigma_a q$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This yields $K+1$ differential equations $$ \\frac{du_i}{dt} = \\frac{1}{\\gamma_i} \\sum_{n=0}^N \\sum_{k=0}^K a_n u_k(t) e_{ink} $$\n",
    "where $\\gamma_i = E[\\psi_i^2]$ and $e_{ink} = E[ \\psi_i \\psi_n \\psi_k]$.\n",
    "\n",
    "Or\n",
    "$$ \\frac{d\\mathbf{u}}{dt}= \\mathbf{A} \\mathbf{u} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def e_ink(i,n,k):\n",
    "    s2 = i + n + k\n",
    "    s = (i + n + k)/2\n",
    "    if numpy.mod(s2,2) == 1:\n",
    "        f = 0\n",
    "    elif ((s<i) | (s<n) | (s<k)):\n",
    "        f = 0\n",
    "    else:\n",
    "        f = numpy.math.factorial(i) * numpy.math.factorial(n) * numpy.math.factorial(k) / numpy.math.factorial(s-i) / numpy.math.factorial(s-n) / numpy.math.factorial(s-k)\n",
    "    return f\n",
    "\n",
    "# Construct A\n",
    "def construct_A(K):\n",
    "    A = numpy.zeros(shape=(K + 1, K + 1))\n",
    "    gamma = numpy.zeros(K+1)\n",
    "    for i in range(K+1):\n",
    "        gamma[i] = numpy.math.factorial(i)\n",
    "        for k in range(K+1):\n",
    "            A[i,k] = -1 / gamma[i] * (a0 * e_ink(i, 0, k) + sigma_a * e_ink(i, 1, k))\n",
    "    return A\n",
    "        \n",
    "# Structure of A\n",
    "K = 6\n",
    "# K = 8\n",
    "K = 12\n",
    "A = construct_A(K)\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_figwidth(fig.get_figwidth() * 2)\n",
    "axes[0].spy(A)\n",
    "plot = axes[1].pcolor(numpy.arange(K + 1), numpy.arange(K + 1), A)\n",
    "fig.colorbar(plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def dU_dt(U, t, A):\n",
    "    # Here U is a vector such that y=U[0] and z=U[1]. This function should return [y', z']\n",
    "    return A.dot(U)\n",
    "\n",
    "# Plot\n",
    "fig, axes  = plt.subplots(2, 2)\n",
    "fig.set_figwidth(fig.get_figwidth() * 2)\n",
    "fig.set_figheight(fig.get_figheight() * 2.5)\n",
    "\n",
    "K_values = numpy.array([[4, 6], [8, 12]])\n",
    "for j in range(2):\n",
    "    for (i, K) in enumerate(K_values[:, j]):\n",
    "        A = construct_A(K)\n",
    "        U0 = numpy.zeros(K+1)\n",
    "        U0[0] = b0\n",
    "        gamma = numpy.array([numpy.math.factorial(i) for i in range(K+1)])\n",
    "        UK = scipy.integrate.odeint(dU_dt, U0, t, args=(A,))\n",
    "        UKmean = UK[:,0]\n",
    "        UKvar = numpy.sum(gamma[1:] * UK[:,1:]**2, axis=1)\n",
    "\n",
    "        axes[i, j].plot(t, UKmean)\n",
    "        axes[i, j].plot(t, UKmean + 2 * numpy.sqrt(UKvar))\n",
    "        axes[i, j].plot(t, UKmean - 2 * numpy.sqrt(UKvar))\n",
    "        axes[i, j].plot(t, umean_exact, 'k--')\n",
    "        axes[i, j].plot(t, umean_exact + 2 * numpy.sqrt(uvar_exact), 'k--')\n",
    "        axes[i, j].plot(t, umean_exact - 2 * numpy.sqrt(uvar_exact), 'k--')\n",
    "        axes[i, j].set_xlabel('Time (s)')\n",
    "        axes[i, j].set_ylabel('Displacement (m)')\n",
    "        axes[i, j].set_title('K = %s' % K)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Discrete projection\n",
    "Also called pseudospectral.\n",
    "$$ u_k(t) = \\frac{1}{\\gamma_k} \\langle(u(t,q),\\psi_k \\rangle = \\frac{1}{\\gamma_i} \\int u(t,q)\\psi_k(q) \\rho_Q(q) dq \\approx \\frac{1}{\\gamma_i} \\sum_{r=1}^R u(t,q^r)\\psi_k(q^r) \\rho_Q(q^r) w^r$$\n",
    "Note requires solving for $u(t,q^r)$. Non-intrusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.polynomial import HermiteE as H\n",
    "\n",
    "qq = numpy.linspace(-2, 2, 100)\n",
    "fig, axes = plt.subplots()\n",
    "for i in range(4): \n",
    "    axes.plot(qq, H.basis(i)(qq), lw=2, label=\"$H_%d$\" % i)\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$u_k(t) = \\frac{1}{\\gamma_k} \\sum_{r=1}^R u(t,q^r) \\psi_k(q^r) \\rho_Q(q^r) w^r$$\n",
    "Use Gauss-Hermite quadrature points. Check normalization. They come in different flavors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "R = 16\n",
    "q, w = numpy.polynomial.hermite_e.hermegauss(R)\n",
    "w = w / numpy.sqrt(2 * numpy.pi)\n",
    "numpy.sum(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$u_k(t) = \\frac{1}{\\gamma_i} \\sum_{r=1}^R u(t,q^r)\\psi_k(q^r)  w^r$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "UKp = numpy.zeros(shape=(nt,K+1))\n",
    "for k in range(K + 1):\n",
    "    UKp[:,k] = numpy.sum(H.basis(k)(q) * w * u(b0, a0 + sigma_a * q, t2), axis=1) / gamma[k]\n",
    "UKpmean = UKp[:,0]\n",
    "UKpvar = numpy.sum(gamma[1:] * UKp[:,1:]**2, axis=1)\n",
    "\n",
    "fig, ax  = plt.subplots()\n",
    "ax.plot(t, UKpmean)\n",
    "ax.plot(t, UKpmean + 2 * numpy.sqrt(UKpvar))\n",
    "ax.plot(t, UKpmean - 2 * numpy.sqrt(UKpvar))\n",
    "ax.plot(t, umean_exact, 'k--')\n",
    "ax.plot(t, umean_exact + 2 * numpy.sqrt(uvar_exact),'k--')\n",
    "ax.plot(t, umean_exact - 2 * numpy.sqrt(uvar_exact),'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Collocation\n",
    "Find coefficients $u_k(t)$ that make $u(t,q^m) \\approx u^K(t,q^m)$, $m=1,\\dots,M$. $q^m$ are collocation points. \n",
    "\n",
    "Least-squares problem.\n",
    "\n",
    "$$  u^K(t,q^m) = \\sum_{k=0}^K u_k(t) \\psi_k(q^m) = u(t,q^m)\\,, m = 1,\\dots,M$$\n",
    "Or\n",
    "$$ \n",
    "\\begin{bmatrix} \n",
    "\\psi_0(q^1) & \\cdots & \\psi_k(q^1) \\\\\n",
    "\\vdots & & \\vdots\\\\\n",
    "\\psi_0(q^M) & \\cdots & \\psi_K(q^M)\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} \n",
    "u_0(t)\\\\\n",
    "\\vdots\\\\\n",
    "u_K(t)\n",
    "\\end{bmatrix} \n",
    "=\\begin{bmatrix} \n",
    "u(t,q^1)\\\\\n",
    "\\vdots\\\\\n",
    "u(t,q^M)\n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "Note rhs requires $M$ solutions, comparable to discrete projection.\n",
    "\n",
    "Let's just use the Gauss-Hermite points. (Scaling seems to work better. What is a good choice?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.polynomial.hermite_e import hermevander\n",
    "from numpy.polynomial.hermite_e import hermefit\n",
    "\n",
    "q = q/1.2\n",
    "rhs = u(b0, a0 + sigma_a * q, t2)\n",
    "rhs = numpy.swapaxes(rhs, 0, 1)\n",
    "\n",
    "UKc = hermefit(q,rhs,K)\n",
    "UKc = numpy.swapaxes(UKc,0,1)\n",
    "\n",
    "UKcmean = UKc[:,0]\n",
    "UKcvar = numpy.sum(gamma[1:] * UKc[:,1:]**2, axis=1)\n",
    "\n",
    "fig, ax  = plt.subplots()\n",
    "ax.plot(t, UKcmean)\n",
    "ax.plot(t, UKcmean + 2 * numpy.sqrt(UKcvar))\n",
    "ax.plot(t, UKcmean - 2 * numpy.sqrt(UKcvar))\n",
    "ax.plot(t, umean_exact, 'k--')\n",
    "ax.plot(t, umean_exact + 2 * numpy.sqrt(uvar_exact), 'k--')\n",
    "ax.plot(t, umean_exact - 2 * numpy.sqrt(uvar_exact), 'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Elliptic PDEs\n",
    "\n",
    "Taking the next step in complexity and adding spatial dependence to our problem we have the strong formulation of an elliptic PDE as\n",
    "$$\\begin{aligned}\n",
    "    &\\mathcal N(u, Q) = F(Q) \\quad x \\in \\mathcal D \\\\\n",
    "    &B(u, Q) = G(Q) \\quad x \\in \\partial D \n",
    "\\end{aligned}$$\n",
    "where the first equation represents a possibly non-linear operator $\\mathcal N$ and the second the corresponding boundary conditions.  Note that we now instead of having a time dependence we have strictly a spatial dependence and hence this has become an infinite-dimensional problem.  The quantity of interest in this case will be defined as\n",
    "$$\n",
    "    y(x) = \\int_\\Gamma u(x, q) \\rho_Q(q) dq\n",
    "$$\n",
    "at $x \\in \\mathcal D$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To turn the strong form equation into a weak one we will take a space of test function $V$ that satisfy zero boundary conditions (essential boundary conditions) and write the differential equation as\n",
    "$$\n",
    "    \\int_{\\mathcal D} \\mathcal N(u, Q) \\mathcal S(v) dx = \\int_{\\mathcal D} F(Q) dx\n",
    "$$\n",
    "where the possible non-linearity of $\\mathcal N$ requires that we may need more complex representations of the functionals containing the test functions $v$, namely $\\mathcal S$ via integration by parts f and $F$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can reterm the problem now as the following:\n",
    "\n",
    "Find a $u \\in V \\otimes Z$, which satisfies\n",
    "$$\n",
    "\\int_\\Gamma \\int_{\\mathcal{D}} N(u, q) S(v(x)) z(q) \\rho_Q(q) dx dq = \\int_\\Gamma \\int_{\\mathcal{D}} F(q) v(x) z(q) \\rho_Q(q) dx dq\n",
    "$$\n",
    "where $V$ is typically an appropriate Sobolev space.\n",
    "\n",
    "Take two basis that will span each of the component spaces that $u$ lives in such that\n",
    "$$\n",
    "    V^J = \\text{span}\\{\\phi_j\\} \\supset V \\quad Z^K = \\text{span}\\{\\Psi_k \\} \\supset Z\n",
    "$$\n",
    "where $\\{\\phi_j\\}$ are any number of traditional basis such as typical finite element basis and $\\{\\Psi_k\\}$ are the spectral polynomial basis already discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We now write the spectral approximation as\n",
    "$$\n",
    "    u^K(x, Q) = \\sum^K_{k=0} u_k(x) \\Psi_k(Q) = \\sum^K_{k=0} \\sum^J_{j=1} u_{jk} \\phi_j(x) \\Psi_k(Q)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Stochastic Galerkin\n",
    "\n",
    "We now need to project the residuals onto to the function test space such that\n",
    "$$\\begin{aligned}\n",
    "    \\int_\\Gamma \\int_{\\mathcal{D}} N(u, q) S(v(x)) z(q) \\rho_Q(q) dx dq &= \\int_\\Gamma \\int_{\\mathcal{D}} F(q) v(x) z(q) \\rho_Q(q) dx dq &\\Rightarrow \\\\\n",
    "    \\int_\\Gamma \\int_{\\mathcal{D}} N\\left(u^K(x, Q), q \\right) S(\\phi_\\ell(x)) \\Psi_i(q) \\rho_Q(q) dx dq &= \\int_\\Gamma \\int_{\\mathcal{D}} F(q) \\phi_\\ell(x) \\Psi_i(q) \\rho_Q(q) dx dq& \\\\\n",
    "    \\int_\\Gamma \\int_{\\mathcal{D}} N\\left(\\sum^K_{k=0} \\sum^J_{j=1} u_{jk} \\phi_j(x) \\Psi_k(Q), q \\right) S(\\phi_\\ell(x)) \\Psi_i(q) \\rho_Q(q) dx dq &= \\int_\\Gamma \\int_{\\mathcal{D}} F(q) \\phi_\\ell(x) \\Psi_i(q) \\rho_Q(q) dx dq&\n",
    "\\end{aligned}$$\n",
    "which needs to hold $\\forall \\ell = 1, \\ldots, J$ and $\\forall i = 0, \\ldots K$ (note that the indices $k$ and $j$ are inside the summation and we avoid their use)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we turn to finding the coefficients $u_{jk}$ by approximating the integrals via quadrature rules formulated here as\n",
    "$$\n",
    "    \\int_\\Gamma z(q) dq \\approx \\sum^R_{r=1} w^r z(q^r).\n",
    "$$\n",
    "where here we have used $R$ quadrature points $q^r$ and $w^r$ are the weights.  Plugging this into the previous formulation we have\n",
    "$$\\begin{aligned}\n",
    "    \\int_\\Gamma \\int_{\\mathcal{D}} N\\left(\\sum^K_{k=0} \\sum^J_{j=1} u_{jk} \\phi_j(x) \\Psi_k(Q), q \\right) S(\\phi_\\ell(x)) \\Psi_i(q) \\rho_Q(q) dx dq &= \\int_\\Gamma \\int_{\\mathcal{D}} F(q) \\phi_\\ell(x) \\Psi_i(q) \\rho_Q(q) dx dq &\\Rightarrow \\\\\n",
    "    \\sum^R_{r=1} w^r \\Psi_i(q^r) \\rho_Q(q^r) \\int_{\\mathcal{D}} N\\left(\\sum^K_{k=0} \\sum^J_{j=1} u_{jk} \\phi_j(x) \\Psi_k(Q), q \\right) S(\\phi_\\ell(x))  dx &= \\sum^R_{r=1} w^r \\Psi_i(q^r) \\rho_Q(q^r)\\int_{\\mathcal{D}} F(q) \\phi_\\ell(x) dx &\n",
    "\\end{aligned}$$\n",
    "If we use standard Gaussian quadrature we have a $J(K+1) \\times J(K+1)$ system of fully coupled equations as we still require these to be $\\forall \\ell = 1, \\ldots, J$ and $\\forall i = 0, \\ldots K$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We need to also discretize the QoI leading to\n",
    "$$\\begin{aligned}\n",
    "    y(x) = \\int_\\Gamma u(x, q) \\rho_Q(q) dq \\approx \\sum^R_{r=1} w^r \\rho_Q(q^r) \\sum^K_{k=0} \\sum^J_{j=1} u_{jk} \\phi_j(x) \\Psi_k(q^r)\n",
    "\\end{aligned}$$\n",
    "where we have slightly simplified the notation by using the same quadrature rule as above.  This is then easily evaluated when the $u_{jk}$ have been determined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Collocation\n",
    "\n",
    "Take $M$ collocation points $q^m \\in \\Gamma$ and Lagrange polynomials for $\\Phi_k$ satisfying the collocation property\n",
    "$$\n",
    "    L_k(q^m) = \\delta_{km}\n",
    "$$\n",
    "at the collocation points we then have\n",
    "$$\n",
    "    u(x, q^m) = u^K(x, q^m) = \\sum^J_{j=1} u_{jm} \\psi_j(x)\n",
    "$$\n",
    "yielding\n",
    "$$\n",
    "    \\int_{\\mathcal{D}} N\\left(\\sum^J_{j=1} u_{jm} \\phi_j(x) \\Psi_k(Q), q^m \\right) S(\\phi_\\ell(x) dx = \\int_{\\mathcal{D}} F(q^m) \\phi_\\ell(x) dx\n",
    "$$\n",
    "where we need this to hold $\\forall \\ell = 1,\\ldots,J$.  Each collocation point $q^m$ we can find the solution for $u_{jm}$ requiring the solution of a $J \\times J$ system.  Note that due to this decoupling this procedure is highly parallelizable and also non-intrusive.  As mentioned previously, the systems resulting from this collocation approach are a form of a stochastic Galerkin approach.  If the collocation points $q^m$ are taken to be the same as the quadrature points $q^r$ and the basis $\\Psi_k$ are the Lagrange basis functions we find the same formulation as we have here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To compute the QoI we again employ a quadrature rule with $R$ points and weights but now we also use Lagrange basis functions to obtain\n",
    "$$\n",
    "    y(x) = \\int_\\Gamma u(x, q) \\rho_Q(q) dq \\approx \\sum^R_{r=1} w^r \\rho_Q(q^r) \\sum^J_{j=1} u_{jr} \\phi_j(x) \\Psi_k(q^r) = \\sum^R_{r=1} w^r \\rho_Q(q^r) \\sum^J_{j=1} u_{jr} \\phi_j(x).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Discrete Projection\n",
    "\n",
    "As usual, discrete projection is the most direct way to approximate the coefficients we desire.  Here we would employ\n",
    "$$\n",
    "    u_k(x) = \\frac{1}{\\gamma_k} \\sum^R_{r=1} u(x, q^r) \\Psi_k(q^r) \\rho_Q(q^r) w^r\n",
    "$$\n",
    "leading to nearly the same method as collocation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Steady-State Heat Equation \n",
    "\n",
    "To have a more concrete example consider the Poisson problem or steady-state heat equation (linear case) with\n",
    "$$\n",
    "    \\alpha \\frac{\\text{d}^2 u}{\\text{d} x^2} = -f(x)\n",
    "$$\n",
    "on $x \\in [-1, 1]$ and BCs $u(-1) = u(1) = 0$ and\n",
    "$$\n",
    "    \\alpha \\sim N(\\bar{\\alpha}, \\sigma^2_\\alpha ).\n",
    "$$\n",
    "\n",
    "We can rewrite this problem in the weak form\n",
    "$$\\begin{aligned}\n",
    "    \\int^1_{-1} \\alpha \\frac{\\text{d}^2 u(x)}{\\text{d} x^2} v(x) dx &= \\int^1_{-1} v(x) f(x) dx \\\\\n",
    "    \\int^1_{-1} \\alpha \\frac{\\text{d} u(x)}{\\text{d} x} \\frac{\\text{d} v(x)}{\\text{d} x} dx &= \\int^1_{-1} v(x) f(x) dx \\\\\n",
    "\\end{aligned}$$\n",
    "which must hold $\\forall v \\in V$.  Placing this in our previous notation we then have\n",
    "$$\n",
    "    \\mathcal{N}(u, Q) = \\alpha \\frac{\\text{d} u(x)}{\\text{d} x} \\quad S(v) = \\frac{\\text{d} v(x)}{\\text{d} x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "From the last example we have\n",
    "$$\n",
    "    \\alpha = \\alpha^N = \\bar{\\alpha} + \\sigma_\\alpha Q = \\sum^1_{n=0} \\alpha_n \\Psi_n(Q)\n",
    "$$\n",
    "where $\\Psi_0(Q) = 1$ and $\\Psi_q(Q) = Q$ are of course the first to Hermite polynomials.  The corresponding density is then\n",
    "$$\n",
    "    \\rho_Q(q) = \\frac{1}{\\sqrt{2 \\pi}} e^{-q^2 / 2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "From our formulation of the general problem we have\n",
    "$$\n",
    "    \\mathcal{N}(u, Q) = (\\bar{\\alpha} + \\sigma_\\alpha Q) \\frac{\\partial u}{\\partial x}, \\quad \\quad S(v) = \\frac{\\text{d} v}{\\text{d} x}\n",
    "$$\n",
    "so that the stochastic weak formulation is therefore\n",
    "$$\n",
    "    \\int_{\\mathbb R} \\int^1_{-1} (\\bar{\\alpha} + \\sigma_\\alpha q) \\frac{\\partial u}{\\partial x} \\frac{\\text{d} v}{\\text{d} x} z(q) \\rho_Q(q) dx dq = -\\int_{\\mathbb R} \\int^1_{-1} f(x) v(x) z(q) \\rho_Q(q) dx dq.\n",
    "$$\n",
    "which must hold $\\forall v \\in H^1_0(-1, 1)$ and $\\forall z \\in L^2_\\rho(\\mathbb R)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Construction of $V^J$\n",
    "\n",
    "To construct the approximate space for the test functions we will use the common hat functions from finite elements:\n",
    "$$\n",
    "    \\phi_j(x) = \\frac{1}{\\Delta x} \\left \\{ \\begin{aligned}\n",
    "        x - x_{j-1} & & x_{j-1} \\leq x < x_j \\\\\n",
    "        x_{j+1} - x & & x_j \\leq x < x_{j+1} \\\\\n",
    "        0 & & \\text{otherwise}\n",
    "    \\end{aligned} \\right .\n",
    "$$\n",
    "with the points $x_j = -1 + j \\cdot \\Delta x$ and $j = 1, \\ldots, J-1$ so the essential boundary conditions are maintained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Construction of $Z^K$\n",
    "\n",
    "The stochastic space will be spanned by the Hermite polynomials as the random variable is normally distributed so that\n",
    "$$\n",
    "    Z^K = \\text{span}\\left \\{\\Psi_k \\right \\}^K_{k=0}\n",
    "$$\n",
    "where the $\\Psi_k(q)$ are Hermite polynomials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Discretized Solution\n",
    "\n",
    "The approximate solution is then in the space $V^J \\otimes Z^K$\n",
    "$$\n",
    "    u^K(x, Q) = \\sum^K_{k=0} \\sum^{J-1}_{j=1} u_{jk} \\phi_j(x) \\Psi_k(q)\n",
    "$$\n",
    "yielding the discretized problem\n",
    "$$\\begin{aligned}\n",
    "    \\int_{\\mathbb R} \\int^1_{-1} (\\bar{\\alpha} + \\sigma_\\alpha q) \\frac{\\partial u}{\\partial x} \\frac{\\text{d} v}{\\text{d} x} z(q) \\rho_Q(q) dx dq &= -\\int_{\\mathbb R} \\int^1_{-1} f(x) v(x) z(q) \\rho_Q(q) dx dq &\\Rightarrow \\\\\n",
    "    \\int_{\\mathbb R} (\\bar{\\alpha} + \\sigma_\\alpha q) \\int^1_{-1} \\frac{\\partial}{\\partial x}\\left[\\sum^K_{k=0} \\sum^{J-1}_{j=1} u_{jk} \\phi_j(x) \\Psi_k(q) \\right] \\frac{\\text{d}}{\\text{d} x} \\left[\\phi_\\ell(x) \\right ] z(q) \\rho_Q(q) dx dq &= -\\int_{\\mathbb R} z(q) \\rho_Q(q) \\left[ \\int^1_{-1} f(x) \\phi_\\ell(x) dx \\right ] dq. & \\\\\n",
    "    \\int_{\\mathbb R} (\\bar{\\alpha} + \\sigma_\\alpha q)  \\sum^K_{k=0} \\sum^{J-1}_{j=1} u_{jk} \\Psi_k(q) \\left [ \\int^1_{-1} \\phi'_j(x) \\phi'_\\ell(x) dx \\right] z(q) \\rho_Q(q) dq &= -\\int_{\\mathbb R} z(q) \\rho_Q(q) \\left[ \\int^1_{-1} f(x) \\phi_\\ell(x) dx \\right ] dq. & \\\\\n",
    "    \\int_{\\mathbb R} (\\bar{\\alpha} + \\sigma_\\alpha q)  \\sum^K_{k=0} \\sum^{J-1}_{j=1} u_{jk} \\Psi_k(q) \\left [ \\int^1_{-1} \\phi'_j(x) \\phi'_\\ell(x) dx \\right] \\Psi_i(q) \\rho_Q(q) dq &= -\\int_{\\mathbb R} \\Psi_i(q) \\rho_Q(q) \\left[ \\int^1_{-1} f(x) \\phi_\\ell(x) dx \\right ] dq. &\n",
    "\\end{aligned}$$\n",
    "which must hold $\\forall \\ell = 1,\\ldots,J$ and $\\forall i = 0, \\ldots, K$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we simplify the notation a bit with the two projections that we can compute before hand we can write\n",
    "$$\\begin{aligned}\n",
    "    &\\Phi_{j\\ell} = \\left \\{ \\begin{aligned}\n",
    "        2 & & j = \\ell \\\\\n",
    "        -1 & & j = \\ell - 1 \\text{ or } j = \\ell + 1 \\\\\n",
    "        0 & & \\text{otherwise}\n",
    "    \\end{aligned} \\right . \\\\\n",
    "    &f_\\ell = \\int^1_{-1} f(x) \\phi_\\ell(x) dx\n",
    "\\end{aligned}$$\n",
    "such that\n",
    "$$\\begin{aligned}\n",
    "    \\int_{\\mathbb R} (\\bar{\\alpha} + \\sigma_\\alpha q)  \\sum^K_{k=0} \\sum^{J-1}_{j=1} u_{jk} \\Psi_k(q) \\left [ \\int^1_{-1} \\phi'_j(x) \\phi'_\\ell(x) dx \\right] \\Psi_i(q) \\rho_Q(q) dq &= -\\int_{\\mathbb R} \\Psi_i(q) \\rho_Q(q) \\left[ \\int^1_{-1} f(x) \\phi_\\ell(x) dx \\right ] dq & \\Rightarrow \\\\\n",
    "    \\sum^{J-1}_{j=1} \\Phi_{j\\ell} \\sum^K_{k=0} u_{jk} \\int_{\\mathbb R} (\\bar{\\alpha} + \\sigma_\\alpha q) \\Psi_k(q) \\Psi_i(q) \\rho_Q(q) dq &= -  f_\\ell \\int_{\\mathbb R} \\Psi_i(q) \\rho_Q(q) dq &\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now due to the orthogonality of the Hermite polynomials\n",
    "$$\n",
    "    \\int_{\\mathbb R} \\Psi_k(q) \\Psi_i(q) \\rho_Q(q) dq = k! \\delta_{ki}\n",
    "$$\n",
    "and the fact we know\n",
    "$$\n",
    "    \\int_{\\mathbb R} \\Psi_\\ell(q) \\rho_Q(q) dq = \\left \\{ \\begin{aligned} 1 & & \\ell = 0 \\\\ 0 & & \\text{otherwise} \\end{aligned} \\right .\n",
    "$$\n",
    "we can construct a system that is $(J - 1) \\times (K + 1) \\times (J - 1) \\times (K + 1)$ in size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Evolution PDEs\n",
    "\n",
    "We now consider the most complex of the systems when we add time to the mix.  Consider a general evolutionary PDE in the form\n",
    "$$\\begin{aligned}\n",
    "    &\\frac{\\partial u}{\\partial t} + \\mathcal{N}(u, Q) = F(Q) & & x \\in \\mathcal{D}, t \\in [0, \\infty) \\\\\n",
    "    &B(u, Q) = G(Q) & & x \\in \\partial \\mathcal{D}, t \\in [0, \\infty) & \\text{Boundary Condition} \\\\\n",
    "    &u(0, x, Q) = I(Q) & & x \\in \\mathcal{D} & \\text{Initial Condition}\n",
    "\\end{aligned}$$\n",
    "where we have from before $\\mathcal{N}$ containing a spatial differential operator, $F$ a source term, along with the boundary conditions and initial conditions.  To solve this problem we will combine the previous two approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The weak deterministic form for the problem is\n",
    "$$\n",
    "    \\int_{\\mathcal{D}} \\frac{\\partial u}{\\partial t} v dx + \\int_{\\mathcal{D}} \\mathcal{N}(u, Q) S(v) dx = \\int_{\\mathcal{D}} F(Q) v dx\n",
    "$$\n",
    "which must hold $\\forall v \\in V$ where the functions in $V$ satisfy essential boundary conditions.  Adding the stochastic component to this we have\n",
    "$$\n",
    "    \\int_\\Gamma \\int_{\\mathcal{D}} \\frac{\\partial u}{\\partial t} v(x) z(q) \\rho_Q(q) dx dq + \\int_\\Gamma \\int_{\\mathcal{D}} \\mathcal{N}(u, Q) S(v(x)) z(q) \\rho_Q(q) dx dq = \\int_\\Gamma \\int_{\\mathcal{D}} F(Q) v(x) z(q) \\rho_Q(q) dx dq\n",
    "$$\n",
    "where now this must hold $\\forall v \\in V$ and $\\forall z \\in Z$.\n",
    "\n",
    "The QoI will be taken to be the expected value\n",
    "$$\n",
    "    y(t, x) = \\int_\\Gamma u(t, x, q) \\rho_Q(q) dq\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here again we take finite dimensional subspaces of the full space $V \\otimes Z$ where\n",
    "$$\n",
    "    V^J = \\text{span}\\{\\phi_j\\} \\supset V \\quad Z^K = \\text{span}\\{\\Psi_k \\} \\supset Z\n",
    "$$\n",
    "leading to the approximate solutions\n",
    "$$\n",
    "    u^K(t, x, Q) = \\sum^K_{k=0} \\sum^J_{j=1} u_{jk}(t) \\phi_j(x) \\Psi_k(Q).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Stochastic Galerkin\n",
    "\n",
    "As before we will use a quadrature rule with $R$ quadrature points $q^r$ and weights $w^r$.  Starting from the stochastic weak form\n",
    "$$\n",
    "    \\int_\\Gamma \\int_{\\mathcal{D}} \\frac{\\partial u}{\\partial t} v(x) z(q) \\rho_Q(q) dx dq + \\int_\\Gamma \\int_{\\mathcal{D}} \\mathcal{N}(u, Q) S(v(x)) z(q) \\rho_Q(q) dx dq = \\int_\\Gamma \\int_{\\mathcal{D}} F(Q) v(x) z(q) \\rho_Q(q) dx dq\n",
    "$$\n",
    "we have the following terms\n",
    "$$\\begin{aligned}\n",
    "    &\\int_\\Gamma \\int_{\\mathcal{D}} \\frac{\\partial u}{\\partial t} v(x) z(q) \\rho_Q(q) dx dq &\\approx& \\sum^R_{r=1} \\Psi_i(q^r) \\rho_Q(q^r) w^r \\sum^K_{k=0} \\sum^J_{j=1} \\frac{\\text{d} u_{jk}}{\\text{d}t} \\Psi_k(q^r) \\int_{\\mathcal{D}} \\phi_j(x) \\phi_\\ell(x) dx \\\\\n",
    "    &\\int_\\Gamma \\int_{\\mathcal{D}} \\mathcal{N}(u, Q) S(v(x)) z(q) \\rho_Q(q) dx dq &\\approx& \\sum^R_{r=1} \\Psi_i(q^r) \\rho_Q(q^r) w^r \\int_{\\mathcal{D}} N\\left(\\sum^K_{k=0} \\sum^J_{j=1} u_{jk} \\phi_j(x) \\Psi_k(q^r), q^r \\right)  S(\\phi_\\ell(x)) dx \\\\\n",
    "    &\\int_\\Gamma \\int_{\\mathcal{D}} F(Q) v(x) z(q) \\rho_Q(q) dx dq &\\approx& \\sum^R_{r=1} \\Psi_i(q^r) \\rho_Q(q^r) w^r \\int_{\\mathcal{D}} F(q^r) \\phi_\\ell(x) dx.\n",
    "\\end{aligned}$$\n",
    "which again holds $\\forall \\ell = 1,\\ldots, J$ and $\\forall i= 0,\\ldots,K$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Once the $u_{jk}(t)$ are found we can evaluate the QoI as\n",
    "$$\n",
    "    y(t, x) = \\int_\\Gamma u(t, x, q) \\rho_Q(q) dq \\approx \\sum^R_{r=1} w^r \\rho_Q(q^r) \\sum^K_{k=0} \\sum^J_{j=1} u_{jk}(t) \\phi_j(x) \\Phi_k(q^r).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Collocation\n",
    "\n",
    "Again using the basis choice for $\\Psi_k(q)$ as Lagrange polynomials with a set of collocation points $q^m$ requiring for simplicity that our quadrature points $q^r$ and collocation points $q^m$ to be identical we then have\n",
    "$$\n",
    "    \\frac{\\text{d} u_{jr}}{\\text{d} t} + \\int_{\\mathcal{D}} N\\left(\\sum^J_{j=1} u_{jr} \\phi_j(x), q^r \\right) S(\\phi_\\ell(x)) dx = \\int_{\\mathcal{D}} F(q^r) \\phi_\\ell(x) dx\n",
    "$$\n",
    "where this holds $\\forall \\ell=1,\\ldots,J$.  The QoI is then approximated with\n",
    "$$\n",
    "    y(t, x) = \\int_\\Gamma u(t, x, q) \\rho_Q(q) dq \\approx \\sum^R_{r=1} w^r \\rho_Q(q^r) \\sum^J_{j=1} u_{jr}(t) \\phi_j(x).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Discrete Projection\n",
    "\n",
    "Here the projection onto the basis forms the systems represented by\n",
    "$$\n",
    "    u_k(t,x) = \\frac{1}{\\gamma_k} \\sum^R_{r=1} u(t, x, q^r) \\Psi_k(q^r) \\rho_Q(q^r) w^r.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Example: Heat Equation\n",
    "\n",
    "$$\n",
    "    \\frac{\\partial u}{\\partial t} = \\kappa(q) \\frac{\\partial^2 u}{\\partial x^2}\\\\\n",
    "    x \\in (-1,1) \\quad u(t, -1) = u(t, 1) = \\alpha \\quad u(0, x) = \\beta e^{-x^2 / \\sigma^2} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def solve_heat_equation(x, U_0, t_0, t_final, kappa=1.0, alpha=0.0, C=0.5):\n",
    "    \"\"\"Solve heat equation using Crank-Nicklson\n",
    "    \n",
    "    \"\"\"\n",
    "    U = U_0[1:-1].copy()\n",
    "    m = U.shape[0]\n",
    "    delta_x = x[1] - x[0]\n",
    "    delta_t = C * delta_x / kappa\n",
    "    N = int((t_final - t_0) / delta_t)\n",
    "\n",
    "    g_0 = lambda t: alpha\n",
    "    g_1 = lambda t: alpha\n",
    "    \n",
    "    r = numpy.ones(m) * delta_t * kappa / (2.0 * delta_x**2)\n",
    "    A = sparse.spdiags([-r, 1.0 + 2.0 * r, -r], [-1, 0, 1], m, m).tocsr()\n",
    "    B = sparse.spdiags([r, 1.0 - 2.0 * r, r], [-1, 0, 1],  m, m).tocsr()\n",
    "    \n",
    "    # Time stepping loop\n",
    "    t = t_0\n",
    "    for n in range(N):\n",
    "        # Construct right-hand side (no BCs)\n",
    "        b = B.dot(U)\n",
    "        b[0] += delta_t * kappa / (2.0 * delta_x**2) * 2.0 * alpha\n",
    "        b[-1] += delta_t * kappa / (2.0 * delta_x**2) * 2.0 * alpha\n",
    "\n",
    "        # Solve system\n",
    "        U = linalg.spsolve(A, b)\n",
    "        t += delta_t\n",
    "    \n",
    "    # Take last time step\n",
    "    delta_t = t_final - (t_0 + delta_t * N)\n",
    "    r = numpy.ones(m) * delta_t * kappa / (2.0 * delta_x**2)\n",
    "    A = sparse.spdiags([-r, 1.0 + 2.0 * r, -r], [-1, 0, 1], m, m).tocsr()\n",
    "    B = sparse.spdiags([r, 1.0 - 2.0 * r, r], [-1, 0, 1],  m, m).tocsr()\n",
    "    b = B.dot(U)\n",
    "    b[0] += delta_t * kappa / (2.0 * delta_x**2) * 2.0 * alpha\n",
    "    b[-1] += delta_t * kappa / (2.0 * delta_x**2) * 2.0 * alpha\n",
    "    U = linalg.spsolve(A, b)\n",
    "    \n",
    "    return U\n",
    "\n",
    "N = 1000\n",
    "kappa_values = numpy.random.uniform(low=0.0, high=1.0, size=N)\n",
    "m = 100\n",
    "x = numpy.linspace(-1, 1, m + 1)\n",
    "\n",
    "alpha = 1.0\n",
    "beta = 1.0\n",
    "sigma = 0.2\n",
    "U_0 = beta * numpy.exp(-x**2 / sigma**2) + alpha\n",
    "\n",
    "U = numpy.ones((N, m + 1)) * alpha\n",
    "for (i, kappa) in enumerate(kappa_values):\n",
    "    U[i, 1:-1] = solve_heat_equation(x, U_0, 0.0, 0.1, kappa=kappa, alpha=alpha)\n",
    "    \n",
    "U_star = numpy.ones(m + 1) * alpha\n",
    "U_star[1:-1] = solve_heat_equation(x, U_0, 0.0, 0.1, kappa=0.5, alpha=alpha)\n",
    "    \n",
    "# Compute statistics\n",
    "U_mean = numpy.sum(U, axis=0) / N\n",
    "\n",
    "# Plot a few solutions\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(fig.get_figwidth() * 2)\n",
    "fig.set_figheight(fig.get_figheight() * 2)\n",
    "axes = fig.add_subplot(1, 1, 1)\n",
    "for (i, kappa) in enumerate(kappa_values):\n",
    "    axes.plot(x, U[i, :], 'gray')#, label=\"$\\kappa = %s$\" % kappa)\n",
    "    axes.set_xlabel(\"x\")\n",
    "    axes.set_ylabel(\"u(x,t)\")\n",
    "    axes.set_title(\"Solution to Heat Equation using CN\")\n",
    "    axes.set_xlim([-1,1])\n",
    "\n",
    "\n",
    "axes.plot(x, U_mean, 'r', label='MC mean')\n",
    "axes.plot(x, U_star, 'c', label='Mean Solution')\n",
    "axes.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Closing Remarks Regarding Stochastic Spectral Methods\n",
    "\n",
    "What follows is a truncated list of comments from Smith section 10.2.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Stochastic Galerkin\n",
    "\n",
    "Is optimal in the $L^2$ sense due to the projection of the residual onto the approximation space (minimized in the given space)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The fully coupled problem which is $J(K+1)\\times J(k+1)$ sometimes can degenerate into the $J \\times J$ size decoupled problems when choosing appropriate basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Sparse grid techniques may need to be used for the quadrature evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Disadvantages\n",
    "   - Can only be used for densities $\\rho_Q$ that have associated orthogonal polynomials.  This also implies that this method may not be suitable for general Bayesian approaches.\n",
    "   - Assumes mutually independent parameters.\n",
    "   - The method is intrusive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Stochastic Collocation\n",
    "\n",
    "Convergence analysis for collocation is based on polynomial approximation theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "These can be constructed by using Lagrange polynomials as the basis and test functions in the Galerkin framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we choose the collocation and quadrature points to be identical then the deterministic and stochastic components decouple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As the number of collocation points change the approximation space changes as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The method is nonintrusive as existing solvers can be used to compute at the $M$ collocation points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Collocation can be used on general parameter distributions including Bayesian techniques.  This again is a consequence due to the requirement that the basis functions $\\Psi$ must be orthogonal with respect to the densities $\\rho_Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Interpolation error for $p$-parameters and $M$ collocation points is\n",
    " $$\n",
    "     f - \\mathcal{I}_M f = \\mathcal{O}(M^{-\\alpha/p})\n",
    " $$\n",
    " where $\\mathcal{I}_M$ is the interpolation operator and $\\alpha$ is the regularity of the solution.  This implies that the accuracy of the method decreases with increasing dimension.  In contrast Monte Carlo convergence rate is $\\mathcal{O}(M^{1/2})$ and hence dimension independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Discrete Projection\n",
    "\n",
    "This method goes by many names including pseudospectral, nonintrusive PC (polynomial chaos), and nonintrusive spectral projection (NISP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The method shares the properties with collocation that the method decouples the deterministic and stochastic components of the solution and is non-intrusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This method is equivalent to collocation if Lagrange polynomials are used as basis functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The method requires the assumption of mutually independent random variables to construct $\\rho_Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Additional Reading\n",
    " - *Spectral Methods for Uncertainty Quantification* by O.P. Le Maitre and O.M. Knio"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
